{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving an Object Detector via TF Serving\n",
    "\n",
    "Date: May 23, 2020\n",
    "\n",
    "Author: Thanaphon Chavengsaksongkram\n",
    "\n",
    "Email: contact@thanaphon.dev\n",
    "\n",
    "\n",
    "# Introduction and Background\n",
    "\n",
    "Serving a machine learning prediction can be done by simply running a model against a batch of collected data on a scheduled task. However, in any larger IT operations, it is often a requirement to serve the predictions on a on-demand basis to various part of the IT infrastructure using a common protocal such as REST API.\n",
    "\n",
    "Furthermore, machine learning models degrade over time (model rotting) and they require updated data to be trained and redeploy to production. This problem introduces many engineering challenges such as versioning, transitioning, deployment and backout, availability, scalability, etc. \n",
    "\n",
    "Tensorflow Serving (TF Serving) is a solution designed to tackle many of the engineering tasks. It is an efficient model server written in C++ that can handle high load, serve multiple versions of the model, and deploy model automatically from source control. TF Serving can also be deployed to private onpremise infrastructure as well asl to managed services such as Google Cloud AI Platform with extra benefits such as built-in monitoring and so on. \n",
    "\n",
    "\n",
    "\n",
    "# Running TF Serving\n",
    "\n",
    "There are many ways to install and run TF Serving: using a Docker image, using system’s package manager, or installing from source. It is recommended by the TensorFlow team to use TF Serving docker image, as it is one of the fastest way to get your model to production.  Docker images are generally platform agnostic and can be deployed to various infrastructure. TF Serving Docker images also support easy configuration with one with GPU and one without.\n",
    "\n",
    "There are two strategies to leverage TF Serving docker images. \n",
    " 1. Use the base TF Serving docker image as a generic model server and configure it to serve a specific SavedModel. \n",
    " 2. Create a new docker image with a SavedModel model baked into it using TF Serving as a base image. \n",
    "\n",
    "The first approach requires less maintenance overhead and it is suitable for most application. The second approach can reduce deployment configuration, which can be useful for deploying a SavedModel to many different platforms.\n",
    "\n",
    "## Model Format for TF Serving\n",
    "\n",
    "TF Serving server expects a SavedModel, which represents a version of a model generated by tf.saved_model.save() function. It is stored as a directory containing computation graph and its associated data. SavedModel also provides a CLI tool called saved_model_cli that can be used to make a test prediction to a SavedModel. \n",
    "\n",
    "Tensorflow 1.x generally saves a model into a frozen graph format. This is not compatibile with TF serving as it expects a SavedModel. Fortunately, SavedModel is just a wrapper of a frozen graph with additional information such as signatures. Converting a frozen graph to a SavedModel is pretty straightforward. \n",
    "\n",
    "# Objective.\n",
    "\n",
    "1. Deploy the model (locally) using Tensorflow Serving. A little tip: Tensorflow Serving might not be able \n",
    "to use the model in its current frozen graph format. Maybe you have to save it in a different format first!\n",
    "2. Create a Tensorflow Serving docker image\n",
    "3. Run the docker image and change `image_example.py` to use the external Tensorflow Serving model.\n",
    "4. (optional) The code and application structure isn't very neat. Feel free to redesign the application structure and\n",
    "code to create a nicer, more usable client (package)\n",
    "\n",
    "# 0. Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Install the prerequisits given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python==4.1.0.25\n",
      "  Downloading opencv_python-4.1.0.25-cp37-cp37m-macosx_10_7_x86_64.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (52.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 52.1 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.15.1\n",
      "  Downloading numpy-1.15.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 2.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp37-cp37m-macosx_10_11_x86_64.whl (105.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 105.8 MB 448 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (0.2.2)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.0.8)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (0.34.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.29.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorflow==1.14.0->-r requirements.txt (line 3)) (3.12.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 3)) (46.4.0.post20200518)\n",
      "Requirement already satisfied: h5py in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0->-r requirements.txt (line 3)) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 3)) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow-serving-api 2.1.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, opencv-python, tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.4\n",
      "    Uninstalling numpy-1.18.4:\n",
      "      Successfully uninstalled numpy-1.18.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed numpy-1.18.4 opencv-python-4.1.0.25 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/thanaphonchavengsaksongkram/Library/Caches/pip/wheels/09/21/3d/d9a06fda40387586027b9963b9558d6b655e0cde968737308f/image-1.5.31-py2.py3-none-any.whl\n",
      "Collecting django\n",
      "  Using cached Django-3.0.6-py3-none-any.whl (7.5 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-7.1.2-cp37-cp37m-macosx_10_10_x86_64.whl (2.2 MB)\n",
      "Requirement already satisfied: six in /Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages (from Image) (1.15.0)\n",
      "Collecting pytz\n",
      "  Using cached pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting asgiref~=3.2\n",
      "  Using cached asgiref-3.2.7-py2.py3-none-any.whl (19 kB)\n",
      "Collecting sqlparse>=0.2.2\n",
      "  Using cached sqlparse-0.3.1-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 517, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/thanaphonchavengsaksongkram/miniconda3/envs/tensorflow/lib/python3.7/site-packages/numpy-1.18.4.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: pytz, asgiref, sqlparse, django, pillow, Image\n",
      "Successfully installed Image-1.5.31 asgiref-3.2.7 django-3.0.6 pillow-7.1.2 pytz-2020.1 sqlparse-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Execute the provided sample script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From image_example.py:92: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From image_example.py:93: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From image_example.py:196: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-05-22 23:51:52.790135: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "!python3 image_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring the given Frozen Graph Model\n",
    "\n",
    "In order to convert the frozen graph to a SavedModel, more information regarding the model is required.\n",
    "\n",
    "## 1.1 Export frozen graph to Tensorboard\n",
    "\n",
    "The first step is to dump the frozen graph into a directory, then inspect it via Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "WARNING:tensorflow:From <ipython-input-34-6ae794422132>:4: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6007\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x172cf8e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "with tf.Session() as sess:\n",
    "    model_filename ='detector_frozen.pb'\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "LOGDIR='tensorboard'\n",
    "train_writer = tf.summary.FileWriter(LOGDIR)\n",
    "train_writer.add_graph(sess.graph)\n",
    "%tensorboard --logdir tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Input and Output layers\n",
    "\n",
    "According to the Tensorboard, the model contains one input layer and 3 output layers.\n",
    "\n",
    "### 1.2.1 Input Layer:\n",
    "- input/input_data\n",
    "\n",
    "### 1.2.2 Output Layers\n",
    "- pred_mbbox/concat_2\n",
    "- pred_sbbox/concat_2\n",
    "- pred_lbbox/concat_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Converting Frozen Graph to SavedModel\n",
    "\n",
    "Export the model into sertis-detector model with a version of 1. The default predict signature definitions will be used for predict API. The input and output tensors are specified based from the information previously obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./serving/sertis-detector/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "export_dir = './serving/sertis-detector/1/'\n",
    "graph_pb = 'detector_frozen.pb'\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "with tf.gfile.GFile(graph_pb, \"rb\") as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "sigs = {}\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # name=\"\" is important to ensure we don't get spurious prefixing\n",
    "    tf.import_graph_def(graph_def, name=\"\")\n",
    "    g = tf.get_default_graph()\n",
    "   # print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "    inp = g.get_tensor_by_name(\"input/input_data:0\")\n",
    "    pred_mbbox = g.get_tensor_by_name(\"pred_mbbox/concat_2:0\")\n",
    "    pred_sbbox = g.get_tensor_by_name(\"pred_sbbox/concat_2:0\")\n",
    "    pred_lbbox = g.get_tensor_by_name(\"pred_lbbox/concat_2:0\")\n",
    "    sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
    "        tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "            {\"in\": inp}, {\"out_mbbox\": pred_mbbox, \"out_sbbox\": pred_sbbox, \"out_lbbox\": pred_lbbox })\n",
    "\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         [tag_constants.SERVING],\n",
    "                                         signature_def_map=sigs)\n",
    "\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Inspect the SavedModel\n",
    "\n",
    "Inspect the SavedModel using saved_model_cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['in'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: unknown_rank\n",
      "      name: input/input_data:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['out_lbbox'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, -1, -1, 3, 85)\n",
      "      name: pred_lbbox/concat_2:0\n",
      "  outputs['out_mbbox'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, -1, -1, 3, 85)\n",
      "      name: pred_mbbox/concat_2:0\n",
      "  outputs['out_sbbox'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, -1, -1, 3, 85)\n",
      "      name: pred_sbbox/concat_2:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir serving/sertis-detector/1 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved model should be ready for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using TF Serving to Serve the Model\n",
    "\n",
    "Before creating a docker image that serves this model, test if the model can be served by running it on the base TF serving image.\n",
    "\n",
    "## 2.1 Download Tensorflow Serving Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from tensorflow/serving\n",
      "\n",
      "\u001b[1Ba4a261c9: Pulling fs layer \n",
      "\u001b[1B20cdee96: Pulling fs layer \n",
      "\u001b[1B60e1d0de: Pulling fs layer \n",
      "\u001b[1B7668deea: Pulling fs layer \n",
      "\u001b[1Bb5699598: Pulling fs layer \n",
      "\u001b[1B8f5dbe31: Pulling fs layer \n",
      "\u001b[1B011e11a2: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:ea44bf657f8cff7b07df12361749ea94628185352836bb08065345f5c8284bae\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for tensorflow/serving:latest\n",
      "docker.io/tensorflow/serving:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Verify that the images have been downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE\n",
      "jwt-api-test         1.0                 f690ec151b72        5 weeks ago         1.04GB\n",
      "tensorflow/serving   latest              7c20ddd72597        4 months ago        251MB\n",
      "python               stretch             b9d77e48a75c        8 months ago        940MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Set environment variables\n",
    "\n",
    "Unfortunately, Jupyter notebook does not persist environment variables set by the shell. So python os package will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_PATH\"] = os.path.join(os.path.sep, os.getcwd(), \"serving\", \"sertis-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thanaphonchavengsaksongkram/Projects/ML-Practical/mle-take-home-test/serving/sertis-detector\n"
     ]
    }
   ],
   "source": [
    "!echo $MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Start Tensorflow Serving Server \n",
    "\n",
    "Start the model server and mount the model to the container file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/sertis-detector\" is already in use by container \"3f6cc2102b4fe8a0c4d96f4ed2415560a4f08f7cc18f113af283dfbac5839430\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -p 8500:8500 -p 8501:8501 --name sertis-detector --detach \\\n",
    "        -v \"$MODEL_PATH:/models/sertis-detector\" \\\n",
    "        -e MODEL_NAME=sertis-detector tensorflow/serving         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Expplaination of each arguments.\n",
    "\n",
    "For reference, a short explaination of each parameters are listed here.\n",
    "\n",
    "#### --detach \n",
    "  run the image in the background\n",
    "\n",
    "#### --name \n",
    "  name the container so we can stop or restart it later.\n",
    "#### -v \"$MODEL_PATH:/models/sertis-detector\"\n",
    "\n",
    "Mount the host file system that contains the model to the container file system at the specified path.\n",
    "\n",
    "#### -e MODEL_NAME=my_mnist_model\n",
    "\n",
    "Sets the container’s MODEL_NAME environment variable, so TF Serving knows which model to serve. By default, it will look for models in the /models directory, and it will automatically serve the latest version it finds.\n",
    "\n",
    "#### --rm\n",
    "Deletes the container when you stop it (no need to clutter your machine with interrupted containers). However, it does not delete the image.\n",
    "\n",
    "#### -p 8500:8500\n",
    "\n",
    "Makes the Docker engine forward the host’s TCP port 8500 to the container’s TCP port 8500. By default, TF Serving uses this port to serve the gRPC API.\n",
    "\n",
    "#### -p 8501:8501\n",
    "Forwards the host’s TCP port 8501 to the container’s TCP port 8501. By default, TF Serving uses this port to serve the REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Verify that the container is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                   PORTS                              NAMES\n",
      "06dfb17894b5        tensorflow/serving   \"/usr/bin/tf_serving…\"   2 hours ago         Up 2 hours               0.0.0.0:8500-8501->8500-8501/tcp   sertis-object-detector\n",
      "cbf5a53282d3        jwt-api-test:1.0     \"gunicorn -b :8080 m…\"   5 weeks ago         Exited (0) 5 weeks ago                                      my-app\n"
     ]
    }
   ],
   "source": [
    "!docker ps --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Testing the model\n",
    "\n",
    "Due to the preprocessing steps required, using CURL may not not appropriate. Instead, The API will  be tested by running a python script predict_via_rest_api which generate a request to the predict endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 predict_via_rest_api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Clean-up\n",
    "\n",
    "Stop and remove the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sertis-object-detector\n",
      "Error: No such container: sertis-object-detector\n",
      "CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                   PORTS               NAMES\n",
      "50a327d2f825        tensorflow/serving   \"/usr/bin/tf_serving…\"   28 seconds ago      Up 27 seconds            8500-8501/tcp       serving_base\n",
      "cbf5a53282d3        jwt-api-test:1.0     \"gunicorn -b :8080 m…\"   5 weeks ago         Exited (0) 5 weeks ago                       my-app\n"
     ]
    }
   ],
   "source": [
    "!docker stop sertis-detector && docker rm sertis-detector\n",
    "!docker ps --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a docker image to serve the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Start Tensorflow Serving Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50a327d2f82589895703cd774122bf30df754908bb6412b43de0b1254acb02d8\n",
      "CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                   PORTS                              NAMES\n",
      "50a327d2f825        tensorflow/serving   \"/usr/bin/tf_serving…\"   1 second ago        Up Less than a second    8500-8501/tcp                      serving_base\n",
      "06dfb17894b5        tensorflow/serving   \"/usr/bin/tf_serving…\"   2 hours ago         Up 2 hours               0.0.0.0:8500-8501->8500-8501/tcp   sertis-object-detector\n",
      "cbf5a53282d3        jwt-api-test:1.0     \"gunicorn -b :8080 m…\"   5 weeks ago         Exited (0) 5 weeks ago                                      my-app\n"
     ]
    }
   ],
   "source": [
    "!docker run -d --name serving_base tensorflow/serving\n",
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Copy the model from local filesystem into container file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp serving/sertis-detector serving_base:/models/sertis-detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Create a docker image with the new change applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:b958cf060a5592c166fab0e00b5e4f9f6a201f79a92ad3e8aa91abfa18dbbc60\n"
     ]
    }
   ],
   "source": [
    "!docker commit --change \"ENV MODEL_NAME sertis-detector\" serving_base tf-sertis-detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Stop TF Serving container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: Cannot kill container: serving_base: No such container: serving_base\n",
      "Error response from daemon: No such container: serving_base\n"
     ]
    }
   ],
   "source": [
    "!docker kill serving_base\n",
    "!docker stop serving_base && docker rm serving_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                   PORTS                              NAMES\n",
      "3f6cc2102b4f        b958cf060a55        \"/usr/bin/tf_serving…\"   22 minutes ago      Up 22 minutes            0.0.0.0:8500-8501->8500-8501/tcp   sertis-detector\n",
      "cbf5a53282d3        jwt-api-test:1.0    \"gunicorn -b :8080 m…\"   5 weeks ago         Exited (0) 5 weeks ago                                      my-app\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Check if the image is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                              TAG                 IMAGE ID            CREATED             SIZE\n",
      "as12production/sertis-object-detector   1.0                 b958cf060a55        24 minutes ago      499MB\n",
      "tf-sertis-detector                      latest              b958cf060a55        24 minutes ago      499MB\n",
      "jwt-api-test                            1.0                 f690ec151b72        5 weeks ago         1.04GB\n",
      "tensorflow/serving                      latest              7c20ddd72597        4 months ago        251MB\n",
      "python                                  stretch             b9d77e48a75c        8 months ago        940MB\n",
      "centurylink/dockerfile-from-image       latest              970eaf375dfd        4 years ago         19.2MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Test the new Image\n",
    "\n",
    "Start a docker container using the new image. Then run the predict_via_rest_api.py script to test its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3f6cc2102b4fe8a0c4d96f4ed2415560a4f08f7cc18f113af283dfbac5839430\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -p 8500:8500 -p 8501:8501 --name sertis-detector --detach \\\n",
    "        -e MODEL_NAME=sertis-detector tf-sertis-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 predict_via_rest_api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sertis-detector\n",
      "Error: No such container: sertis-detector\n"
     ]
    }
   ],
   "source": [
    "!docker stop sertis-detector && docker rm sertis-detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy to Docker hub\n",
    "\n",
    "Deploy the newly created image to docker hub for distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Tag the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag b958cf060a55 as12production/sertis-object-detector:1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Log into docker hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!docker login --username as12production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Push the image to docker hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/as12production/sertis-object-detector]\n",
      "\n",
      "\u001b[1B4b169550: Preparing \n",
      "\u001b[1Bd98b810c: Preparing \n",
      "\u001b[1B55bd8fcf: Preparing \n",
      "\u001b[1B61ac0e5e: Preparing \n",
      "\u001b[1B3374c0b5: Preparing \n",
      "\u001b[1Bfb8f161b: Preparing \n",
      "\u001b[1B43ea46a8: Preparing \n",
      "\u001b[1Bfcc4a1a8: Preparing \n",
      "\u001b[9B4b169550: Pushed   248.3MB/248.3MBserving \u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K1.0: digest: sha256:4b6e58f60a825e34a39b968610e9af3deec30f0acdd9c4493f9820a892784ec0 size: 2202\n"
     ]
    }
   ],
   "source": [
    "!docker push as12production/sertis-object-detector:1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hub.docker.com/r/as12production/sertis-object-detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Test the docker hub image\n",
    "### 4.4.1 Remove old images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No such image: tf-sertis-detector\n",
      "Untagged: as12production/sertis-object-detector:1.0\n",
      "Untagged: as12production/sertis-object-detector@sha256:4b6e58f60a825e34a39b968610e9af3deec30f0acdd9c4493f9820a892784ec0\n",
      "Deleted: sha256:b958cf060a5592c166fab0e00b5e4f9f6a201f79a92ad3e8aa91abfa18dbbc60\n",
      "Deleted: sha256:3559d4427da077b38cddcf889c1a4c9b385f7f6d58a7daf2d68db863955e7ee9\n",
      "Deleted: sha256:7c20ddd72597be37ca64e0393fdc219b8906b8709becacf51f746c9f812a8121\n",
      "Deleted: sha256:a4cc2c00fdca74c89dec852801b1824cb5fd22e90ac97be2e84357ea3145f95b\n",
      "Deleted: sha256:6decd594d39b31482b1d147650d855358a26fc600dc06a67ca81228bc7feef6c\n",
      "Deleted: sha256:6e949cb9cd885c847557035e725919b879b201f37df07e2b19fae80a088058a3\n",
      "Deleted: sha256:2d95a023d1fa3fc0caabcc97ee5dcdb7e75dd79e24567431f8e34047ae660ee7\n",
      "Deleted: sha256:7c52cdc1e32d67e3d5d9f83c95ebe18a58857e68bb6985b0381ebdcec73ff303\n",
      "Deleted: sha256:a3c2e83788e20188bb7d720f36ebeef2f111c7b939f1b19aa1b4756791beece0\n",
      "Deleted: sha256:61199b56f34827cbab596c63fd6e0ac0c448faa7e026e330994818190852d479\n",
      "Deleted: sha256:2dc9f76fb25b31e0ae9d36adce713364c682ba0d2fa70756486e5cedfaf40012\n",
      "Error: No such image: tensorflow/serving\n",
      "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n",
      "jwt-api-test        1.0                 f690ec151b72        5 weeks ago         1.04GB\n",
      "python              stretch             b9d77e48a75c        8 months ago        940MB\n"
     ]
    }
   ],
   "source": [
    "!docker rmi tf-sertis-detector\n",
    "!docker rmi as12production/sertis-object-detector\n",
    "!docker rmi tensorflow/serving  \n",
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Pull the image from docker hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: Pulling from as12production/sertis-object-detector\n",
      "\n",
      "\u001b[1Ba4a261c9: Pulling fs layer \n",
      "\u001b[1B20cdee96: Pulling fs layer \n",
      "\u001b[1B60e1d0de: Pulling fs layer \n",
      "\u001b[1B7668deea: Pulling fs layer \n",
      "\u001b[1Bb5699598: Pulling fs layer \n",
      "\u001b[1B8f5dbe31: Pulling fs layer \n",
      "\u001b[1B011e11a2: Pulling fs layer \n",
      "\u001b[1B075f0126: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:4b6e58f60a825e34a39b968610e9af3deec30f0acdd9c4493f9820a892784ec0[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for as12production/sertis-object-detector:1.0\n",
      "docker.io/as12production/sertis-object-detector:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker pull as12production/sertis-object-detector:1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 List all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                              TAG                 IMAGE ID            CREATED             SIZE\n",
      "as12production/sertis-object-detector   1.0                 b958cf060a55        29 minutes ago      499MB\n",
      "jwt-api-test                            1.0                 f690ec151b72        5 weeks ago         1.04GB\n",
      "python                                  stretch             b9d77e48a75c        8 months ago        940MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 Start the downloaded container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -p 8500:8500 -p 8501:8501 --name sertis-detector --detach \\\n",
    "        -e MODEL_NAME=sertis-detector as12production/sertis-object-detector:1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5 Inspect the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522\",\n",
      "        \"Created\": \"2020-05-22T16:35:13.9663642Z\",\n",
      "        \"Path\": \"/usr/bin/tf_serving_entrypoint.sh\",\n",
      "        \"Args\": [],\n",
      "        \"State\": {\n",
      "            \"Status\": \"running\",\n",
      "            \"Running\": true,\n",
      "            \"Paused\": false,\n",
      "            \"Restarting\": false,\n",
      "            \"OOMKilled\": false,\n",
      "            \"Dead\": false,\n",
      "            \"Pid\": 6785,\n",
      "            \"ExitCode\": 0,\n",
      "            \"Error\": \"\",\n",
      "            \"StartedAt\": \"2020-05-22T16:35:14.2965373Z\",\n",
      "            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n",
      "        },\n",
      "        \"Image\": \"sha256:b958cf060a5592c166fab0e00b5e4f9f6a201f79a92ad3e8aa91abfa18dbbc60\",\n",
      "        \"ResolvConfPath\": \"/var/lib/docker/containers/ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522/resolv.conf\",\n",
      "        \"HostnamePath\": \"/var/lib/docker/containers/ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522/hostname\",\n",
      "        \"HostsPath\": \"/var/lib/docker/containers/ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522/hosts\",\n",
      "        \"LogPath\": \"/var/lib/docker/containers/ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522/ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522-json.log\",\n",
      "        \"Name\": \"/sertis-detector\",\n",
      "        \"RestartCount\": 0,\n",
      "        \"Driver\": \"overlay2\",\n",
      "        \"Platform\": \"linux\",\n",
      "        \"MountLabel\": \"\",\n",
      "        \"ProcessLabel\": \"\",\n",
      "        \"AppArmorProfile\": \"\",\n",
      "        \"ExecIDs\": null,\n",
      "        \"HostConfig\": {\n",
      "            \"Binds\": null,\n",
      "            \"ContainerIDFile\": \"\",\n",
      "            \"LogConfig\": {\n",
      "                \"Type\": \"json-file\",\n",
      "                \"Config\": {}\n",
      "            },\n",
      "            \"NetworkMode\": \"default\",\n",
      "            \"PortBindings\": {\n",
      "                \"8500/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"\",\n",
      "                        \"HostPort\": \"8500\"\n",
      "                    }\n",
      "                ],\n",
      "                \"8501/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"\",\n",
      "                        \"HostPort\": \"8501\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"RestartPolicy\": {\n",
      "                \"Name\": \"no\",\n",
      "                \"MaximumRetryCount\": 0\n",
      "            },\n",
      "            \"AutoRemove\": true,\n",
      "            \"VolumeDriver\": \"\",\n",
      "            \"VolumesFrom\": null,\n",
      "            \"CapAdd\": null,\n",
      "            \"CapDrop\": null,\n",
      "            \"Capabilities\": null,\n",
      "            \"Dns\": [],\n",
      "            \"DnsOptions\": [],\n",
      "            \"DnsSearch\": [],\n",
      "            \"ExtraHosts\": null,\n",
      "            \"GroupAdd\": null,\n",
      "            \"IpcMode\": \"private\",\n",
      "            \"Cgroup\": \"\",\n",
      "            \"Links\": null,\n",
      "            \"OomScoreAdj\": 0,\n",
      "            \"PidMode\": \"\",\n",
      "            \"Privileged\": false,\n",
      "            \"PublishAllPorts\": false,\n",
      "            \"ReadonlyRootfs\": false,\n",
      "            \"SecurityOpt\": null,\n",
      "            \"UTSMode\": \"\",\n",
      "            \"UsernsMode\": \"\",\n",
      "            \"ShmSize\": 67108864,\n",
      "            \"Runtime\": \"runc\",\n",
      "            \"ConsoleSize\": [\n",
      "                0,\n",
      "                0\n",
      "            ],\n",
      "            \"Isolation\": \"\",\n",
      "            \"CpuShares\": 0,\n",
      "            \"Memory\": 0,\n",
      "            \"NanoCpus\": 0,\n",
      "            \"CgroupParent\": \"\",\n",
      "            \"BlkioWeight\": 0,\n",
      "            \"BlkioWeightDevice\": [],\n",
      "            \"BlkioDeviceReadBps\": null,\n",
      "            \"BlkioDeviceWriteBps\": null,\n",
      "            \"BlkioDeviceReadIOps\": null,\n",
      "            \"BlkioDeviceWriteIOps\": null,\n",
      "            \"CpuPeriod\": 0,\n",
      "            \"CpuQuota\": 0,\n",
      "            \"CpuRealtimePeriod\": 0,\n",
      "            \"CpuRealtimeRuntime\": 0,\n",
      "            \"CpusetCpus\": \"\",\n",
      "            \"CpusetMems\": \"\",\n",
      "            \"Devices\": [],\n",
      "            \"DeviceCgroupRules\": null,\n",
      "            \"DeviceRequests\": null,\n",
      "            \"KernelMemory\": 0,\n",
      "            \"KernelMemoryTCP\": 0,\n",
      "            \"MemoryReservation\": 0,\n",
      "            \"MemorySwap\": 0,\n",
      "            \"MemorySwappiness\": null,\n",
      "            \"OomKillDisable\": false,\n",
      "            \"PidsLimit\": null,\n",
      "            \"Ulimits\": null,\n",
      "            \"CpuCount\": 0,\n",
      "            \"CpuPercent\": 0,\n",
      "            \"IOMaximumIOps\": 0,\n",
      "            \"IOMaximumBandwidth\": 0,\n",
      "            \"MaskedPaths\": [\n",
      "                \"/proc/asound\",\n",
      "                \"/proc/acpi\",\n",
      "                \"/proc/kcore\",\n",
      "                \"/proc/keys\",\n",
      "                \"/proc/latency_stats\",\n",
      "                \"/proc/timer_list\",\n",
      "                \"/proc/timer_stats\",\n",
      "                \"/proc/sched_debug\",\n",
      "                \"/proc/scsi\",\n",
      "                \"/sys/firmware\"\n",
      "            ],\n",
      "            \"ReadonlyPaths\": [\n",
      "                \"/proc/bus\",\n",
      "                \"/proc/fs\",\n",
      "                \"/proc/irq\",\n",
      "                \"/proc/sys\",\n",
      "                \"/proc/sysrq-trigger\"\n",
      "            ]\n",
      "        },\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/var/lib/docker/overlay2/919ade47a8758cb34572da967e4c80ade7044a224d17607a9d913f2b405202e1-init/diff:/var/lib/docker/overlay2/ea660bf6f1d74d7007ca87c7c76aa5f70255288c6a9b8d8755a74831e4c31624/diff:/var/lib/docker/overlay2/c02465433b84490bc0a3e1a826d85ae4dfd1821f0430a32317ad1ac4537c62e9/diff:/var/lib/docker/overlay2/a7cd4efddb304376745f1b567bc03e685c24c3bc4903e77bcae7ee7d8d30b37c/diff:/var/lib/docker/overlay2/dd39f3977a94c0c7b522bb4a2ca4156146a32a682187aa37609226abb873f90a/diff:/var/lib/docker/overlay2/73e3f3dd9b9adab3269336e5d3a8ac7dc149166a55964078caffc21e044ccc2c/diff:/var/lib/docker/overlay2/ba5ae2f61a135b74d5b0ff70aea02588b050134b325b51af7cf5f3395029073a/diff:/var/lib/docker/overlay2/6d918807d973566ccc6bb17ba0f88f24f6126f004c53e4f2cc69bde1e84852b4/diff:/var/lib/docker/overlay2/029dc0958bf8527dfecf2e5545129a308d7a27746f9a0de59ccb9c4697940f47/diff:/var/lib/docker/overlay2/11f9cb0331912e55b56b511c6af1b37aae47d36c6e186d46a6ff274af97fb3c4/diff\",\n",
      "                \"MergedDir\": \"/var/lib/docker/overlay2/919ade47a8758cb34572da967e4c80ade7044a224d17607a9d913f2b405202e1/merged\",\n",
      "                \"UpperDir\": \"/var/lib/docker/overlay2/919ade47a8758cb34572da967e4c80ade7044a224d17607a9d913f2b405202e1/diff\",\n",
      "                \"WorkDir\": \"/var/lib/docker/overlay2/919ade47a8758cb34572da967e4c80ade7044a224d17607a9d913f2b405202e1/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"Mounts\": [],\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"ea7018f0e1ff\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8500/tcp\": {},\n",
      "                \"8501/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": true,\n",
      "            \"OpenStdin\": true,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"MODEL_NAME=sertis-detector\",\n",
      "                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"MODEL_BASE_PATH=/models\"\n",
      "            ],\n",
      "            \"Cmd\": null,\n",
      "            \"Image\": \"as12production/sertis-object-detector:1.0\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": [\n",
      "                \"/usr/bin/tf_serving_entrypoint.sh\"\n",
      "            ],\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"maintainer\": \"gvasudevan@google.com\",\n",
      "                \"tensorflow_serving_github_branchtag\": \"2.1.0\",\n",
      "                \"tensorflow_serving_github_commit\": \"d83512c6b5b2b8433df2fd61bbbfb22e0295b3d3\"\n",
      "            }\n",
      "        },\n",
      "        \"NetworkSettings\": {\n",
      "            \"Bridge\": \"\",\n",
      "            \"SandboxID\": \"3a8df7040862bda053bb114cd24d8b30f382896aa6f773985763b760298fe424\",\n",
      "            \"HairpinMode\": false,\n",
      "            \"LinkLocalIPv6Address\": \"\",\n",
      "            \"LinkLocalIPv6PrefixLen\": 0,\n",
      "            \"Ports\": {\n",
      "                \"8500/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"0.0.0.0\",\n",
      "                        \"HostPort\": \"8500\"\n",
      "                    }\n",
      "                ],\n",
      "                \"8501/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"0.0.0.0\",\n",
      "                        \"HostPort\": \"8501\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"SandboxKey\": \"/var/run/docker/netns/3a8df7040862\",\n",
      "            \"SecondaryIPAddresses\": null,\n",
      "            \"SecondaryIPv6Addresses\": null,\n",
      "            \"EndpointID\": \"0e1f4061c0a630b5c6b308ff231afb124afa979455ab135154542c420d91a89b\",\n",
      "            \"Gateway\": \"172.17.0.1\",\n",
      "            \"GlobalIPv6Address\": \"\",\n",
      "            \"GlobalIPv6PrefixLen\": 0,\n",
      "            \"IPAddress\": \"172.17.0.2\",\n",
      "            \"IPPrefixLen\": 16,\n",
      "            \"IPv6Gateway\": \"\",\n",
      "            \"MacAddress\": \"02:42:ac:11:00:02\",\n",
      "            \"Networks\": {\n",
      "                \"bridge\": {\n",
      "                    \"IPAMConfig\": null,\n",
      "                    \"Links\": null,\n",
      "                    \"Aliases\": null,\n",
      "                    \"NetworkID\": \"7ebccccd906873b483c625a2f33ac8fd38c06b03b6d6e69d92eaf8edfbe9401d\",\n",
      "                    \"EndpointID\": \"0e1f4061c0a630b5c6b308ff231afb124afa979455ab135154542c420d91a89b\",\n",
      "                    \"Gateway\": \"172.17.0.1\",\n",
      "                    \"IPAddress\": \"172.17.0.2\",\n",
      "                    \"IPPrefixLen\": 16,\n",
      "                    \"IPv6Gateway\": \"\",\n",
      "                    \"GlobalIPv6Address\": \"\",\n",
      "                    \"GlobalIPv6PrefixLen\": 0,\n",
      "                    \"MacAddress\": \"02:42:ac:11:00:02\",\n",
      "                    \"DriverOpts\": null\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!docker inspect ea7018f0e1ff409a97437020fe0e5c903b6cb254ae77ebcd81618d28939dc522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Execute the test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 predict_via_rest_api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sertis-detector\n",
      "Error: No such container: sertis-detector\n",
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                   PORTS               NAMES\n",
      "cbf5a53282d3        jwt-api-test:1.0    \"gunicorn -b :8080 m…\"   5 weeks ago         Exited (0) 5 weeks ago                       my-app\n"
     ]
    }
   ],
   "source": [
    "!docker stop sertis-detector  && docker rm sertis-detector\n",
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Conclusion\n",
    "\n",
    "In this task, a frozen graph has been successfully converted to a SavedModel and deployed to Tensorflow Serving. A new docker image is created with the model included and is deployed to Docker hub. \n",
    "\n",
    "\n",
    "## 5.1 Future Task \n",
    "\n",
    "Currently, the model isn't quite user friendly as it requires a specialized image preprocessing before the input can be fed into the prediction service. I believe that the transformation pipeline should be included into the pipeline or create a front-end API that performs this transformation. It is a lot more user friendly if the end API accepts a base64 encoding image and return the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
